# Multi-LLM Agent 전역 설정
# 이 파일을 복사하여 프로젝트별로 커스터마이징하세요.

defaults:
  # 각 LLM 호출 타임아웃 (초)
  timeout: 120

  # 실패 시 재시도 횟수
  max_retries: 3

  # 기본 temperature (창의성 조절, 0~1)
  temperature: 0.7

  # 기본 max_tokens
  max_tokens: 4096

# LLM 프로바이더별 설정
providers:
  openai:
    base_url: "https://api.openai.com/v1"
    default_model: "gpt-4o"
    # API 키는 환경 변수 OPENAI_API_KEY로 설정
    models:
      - gpt-4o           # 최신 멀티모달, 빠름
      - gpt-4o-mini      # 저비용, 빠름
      - gpt-4-turbo      # 고성능
      - o1-preview       # 추론 특화
      - o1-mini          # 추론, 저비용

  gemini:
    base_url: "https://generativelanguage.googleapis.com/v1beta"
    default_model: "gemini-2.0-flash"
    # API 키는 환경 변수 GOOGLE_API_KEY로 설정
    models:
      - gemini-2.0-flash     # 빠름, 저비용
      - gemini-1.5-pro       # 고성능, 긴 컨텍스트
      - gemini-1.5-flash     # 빠름

  anthropic:
    base_url: "https://api.anthropic.com/v1"
    default_model: "claude-sonnet-4-20250514"
    # API 키는 환경 변수 ANTHROPIC_API_KEY로 설정
    models:
      - claude-sonnet-4-20250514  # 균형잡힌 성능
      - claude-opus-4-20250514    # 최고 성능
      - claude-haiku-3-5-20241022 # 빠름, 저비용

  ollama:
    base_url: "http://localhost:11434"
    default_model: "llama3.2"
    # 로컬 실행, API 키 불필요
    models:
      - llama3.2         # 범용
      - codellama        # 코드 특화
      - mistral          # 범용
      - mixtral          # 고성능

# 로깅 설정
logging:
  # 로그 레벨: DEBUG, INFO, WARNING, ERROR
  level: "INFO"

  # 대화 내용 저장 여부
  save_conversations: true

  # 로그 출력 디렉토리
  output_dir: "./logs"

  # 로그 파일 형식: json, text
  format: "json"

# 비용 추정 설정 (1K 토큰당 USD)
cost_estimation:
  openai:
    gpt-4o:
      input: 0.0025
      output: 0.01
    gpt-4o-mini:
      input: 0.00015
      output: 0.0006
  gemini:
    gemini-2.0-flash:
      input: 0.0001
      output: 0.0004
    gemini-1.5-pro:
      input: 0.00125
      output: 0.005
  anthropic:
    claude-sonnet-4-20250514:
      input: 0.003
      output: 0.015
  ollama:
    # 로컬 실행으로 무료
    default:
      input: 0
      output: 0
